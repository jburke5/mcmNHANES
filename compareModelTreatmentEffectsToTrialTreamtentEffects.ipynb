{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect size on BP loweing from older data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BP lowering effect from Turnbull, F., Blood Pressure Lowering Treatment Trialists' Collaboration. (2003). Effects of different blood-pressure-lowering regimens on major cardiovascular events: results of prospectively-designed overviews of randomised trials. Lancet, 362(9395), 1527–1535. http://doi.org/10.1016/S0140-6736(03)14739-3\n",
    "# SBP is a weighted average of the 3 groups = \n",
    "weightedSBPLowering = (18229 * 5 + 7482 * 8 + 20888 * 4) / (18229 + 7482 + 20888)\n",
    "weightedDBPLowering = (18229 * 2 + 7482 * 4 + 20888 * 3) / (18229 + 7482 + 20888)\n",
    "print(f\"average BP lowering: {weightedSBPLowering:.2f}/{weightedDBPLowering:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of effect sizes on BP lowering and their clinical impact from slightly newer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialists' Collaboration, T. B. P. L. T. (2014). Blood pressure-lowering treatment based on cardiovascular risk: a meta-analysis of individual patient data. The Lancet, 384(9943), 591–598. http://doi.org/10.1016/S0140-6736(14)61212-5\n",
    "weightedSBPLowering = (25236 * 4.4 + 12256 * 6.1 + 8674 * 7.5 + 5751*6.1) / (25236 + 12256 + 8674 + 5751)\n",
    "weightedDBPLowering = (25236 * 3.0 + 12256 * 3.1 + 8674 * 3.5 + 5751*2.6) / (25236 + 12256 + 8674 + 5751)\n",
    "print(f\"average BP lowering: {weightedSBPLowering:.2f}/{weightedDBPLowering:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedStrokeRR = (25236 * 0.75 + 12256 * 0.83 + 8674 * 0.84 + 5751*0.84) / (25236 + 12256 + 8674 + 5751)\n",
    "print(f\"weighted stroke RR: {weightedStrokeRR:.2f}\")\n",
    "\n",
    "weightedCHDRR = (24755*0.85 + 12596*0.94 + 8817*0.85 + 5876*0.87)/(24755+12596+8817+5876)\n",
    "print(f\"weighted CHD RR: {weightedCHDRR:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import numpy.random as npRand\n",
    "import pandas as pd\n",
    "import copy\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "os.chdir(\"/Users/burke/Documents/research/bpCog/microsim\")\n",
    "from microsim.outcome import OutcomeType\n",
    "from microsim.population import NHANESDirectSamplePopulation\n",
    "from microsim.smoking_status import SmokingStatus\n",
    "from microsim.race_ethnicity import NHANESRaceEthnicity\n",
    "from microsim.outcome_model_type import OutcomeModelType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility methods to filter the population adn add a BP med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crudely filter for possible allhat candidates\n",
    "def ageBPFilter(person):\n",
    "    return person._age[0] > 55 and person._sbp[0] > 140 and person._sbp[0] < 180 and person._dbp[0] > 90 and person._dbp[0] < 110\n",
    "\n",
    "# add a BP medication to a person using the BP med effect\n",
    "def addABPMed(person):\n",
    "    return {'_antiHypertensiveCount' : 1, '_bpMedsAdded' : 1}, {'_sbp': - 1* weightedSBPLowering, '_dbp' : -1 * weightedDBPLowering}, {OutcomeType.STROKE : 0.79, OutcomeType.MI : 0.87}\n",
    "\n",
    "# add a BP medication to a person using the BP med effect\n",
    "#def addABPMedFromADistribution(person):\n",
    "#    return {'_antiHypertensiveCount' : 1}, {'_sbp': - 1* np.random.normal(weightedSBPLowering, 3.5), '_dbp' : -1 * np.random.normal(weightedDBPLowering, 2)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a baseline population and one where <b>everybody</b> gets an additional BP med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAndAdvancePopulation(popSize, numberOfClones, years):\n",
    "    basePop99 =  NHANESDirectSamplePopulation(n=popSize, year=1999, filter=ageBPFilter)\n",
    "    basePop01 =  NHANESDirectSamplePopulation(n=popSize, year=2001, filter=ageBPFilter)\n",
    "    basePop03 = NHANESDirectSamplePopulation(n=popSize, year=2003, filter=ageBPFilter)\n",
    "    basePop99._people = basePop99._people[basePop99._people.notnull()]\n",
    "    basePop01._people = basePop01._people[basePop01._people.notnull()]\n",
    "    basePop03._people = basePop03._people[basePop03._people.notnull()]\n",
    "    \n",
    "    basePop = basePop99\n",
    "    basePop._people = basePop._people.append([basePop01._people,basePop03._people])\n",
    "    \n",
    "    baselinePop = NHANESDirectSamplePopulation(n=popSize, year=2001, filter=ageBPFilter) # start the sim in 2001\n",
    "    popExtraBpMed = NHANESDirectSamplePopulation(n=popSize, year=2001, filter=ageBPFilter) # start the sim in 2001\n",
    "    \n",
    "    clonedPeople = []\n",
    "    for i,person in basePop._people.iteritems():\n",
    "        for copyCount in range (1,numberOfClones):\n",
    "            clonedPeople.append(person.slightly_randomly_modify_baseline_risk_factors(basePop._risk_model_repository))\n",
    "    baselinePop._people = pd.Series(clonedPeople)\n",
    "\n",
    "    clonedPeople2 = []\n",
    "    for i,person in basePop._people.iteritems():\n",
    "        for copyCount in range (1,numberOfClones):\n",
    "            clonedPeople2.append(person.slightly_randomly_modify_baseline_risk_factors(basePop._risk_model_repository))\n",
    "    popExtraBpMed._people = pd.Series(clonedPeople2)\n",
    "    \n",
    "    baselinePop._people = baselinePop._people[baselinePop._people.notnull()]\n",
    "    baselinePop._people = baselinePop._people.loc[[person.allhat_candidate(0) ==True for person in baselinePop._people]]\n",
    "    popExtraBpMed._people = popExtraBpMed._people[popExtraBpMed._people.notnull()]\n",
    "    popExtraBpMed._people = popExtraBpMed._people.loc[[person.allhat_candidate(0) ==True for person in popExtraBpMed._people]]\n",
    "    \n",
    "    popExtraBpMed.set_bp_treatment_strategy(addABPMed)\n",
    "    baselinePop.advance_multi_process(years)\n",
    "    popExtraBpMed.advance_multi_process(years)\n",
    "    \n",
    "    return (baselinePop, popExtraBpMed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAndAdvanceUnselectedPopulation(popSize, years):\n",
    "    baselinePop = NHANESDirectSamplePopulation(n=popSize, year=2001) # start the sim in 2001\n",
    "    #popExtraBpMed = NHANESDirectSamplePopulation(n=popSize, year=2001) # start the sim in 2001\n",
    "    #popExtraBpMed.set_bp_treatment_strategy(addABPMed)\n",
    "\n",
    "    baselinePop.advance_multi_process(years)\n",
    "    #popExtraBpMed.advance_multi_process(years)\n",
    "    \n",
    "    #return (baselinePop, popExtraBpMed)\n",
    "    return (baselinePop, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizePopulation(pop, description):\n",
    "    print(f\"Baseline BP in {description} population: {pd.Series([x._sbp[0] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"BP in first wave in {description} population: {pd.Series([x._sbp[1] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"Last BP in {description} population: {pd.Series([x._sbp[-1] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"BP meds at baseline in {description} population: {pd.Series([x._antiHypertensiveCount[0] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"BP meds in first wave {description} population: {pd.Series([x._antiHypertensiveCount[1] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"BP meds in last wave {description} population: {pd.Series([x._antiHypertensiveCount[-1] for i, x in  pop._people.iteritems()]).mean():.2f}\")\n",
    "    print(f\"# dead in {description} {pd.Series([x.is_dead() for i, x in  pop._people.iteritems()]).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDFForPopulation(pop, numYears):\n",
    "    data = {}\n",
    "    for year in range(1,numYears+1):\n",
    "        #popAtStartOfWave = pop.get_people_alive_at_the_start_of_wave(year)\n",
    "        data['mi' + str(year)] = [x.has_mi_during_wave(year) for _,x in  pop._people.iteritems()]\n",
    "        data['stroke' + str(year)] = [x.has_stroke_during_wave(year) for _,x in  pop._people.iteritems()]\n",
    "        data['dead' + str(year)] = [x.is_dead() and len(x._age)==1 for i,x in  pop._people.iteritems()]\n",
    "    \n",
    "    data['age'] = [x._age[0] for i,x in  pop._people.iteritems()]\n",
    "    data['allhat'] = [x.allhat_candidate(0) for i,x in  pop._people.iteritems()]\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def getSimpleDFForPopulation(pop):\n",
    "    return pd.DataFrame({'mi': [x.has_mi_during_simulation() for i,x in  pop._people.iteritems()],\n",
    "                         'stroke' : [x.has_stroke_during_simulation() for i,x in  pop._people.iteritems()],\n",
    "                         'yearsOfObservation' : [x.years_in_simulation() for i, x in pop._people.iteritems()]})\n",
    "\n",
    "\n",
    "def getReshapedLongDF(untreatedEvents, treatedEvents, untreated_overallEvents, treated_overallEvents):\n",
    "    untreatedEvents['treatment'] = 0\n",
    "    treatedEvents['treatment'] = 1\n",
    "    allEvents = pd.concat([untreatedEvents, treatedEvents], ignore_index=True)\n",
    "    allEvents['id'] = allEvents.index\n",
    "    \n",
    "    reshapedLong = pd.wide_to_long(allEvents,stubnames=['mi', 'stroke', 'dead'], i='id', j='wave')\n",
    "    reshapedLong = reshapedLong.sort_index()\n",
    "    reshapedLong['waveAsColumn'] = reshapedLong.index.get_level_values('wave')\n",
    "    reshapedLong.loc[reshapedLong.dead, 'diedInWaveTemp'] = reshapedLong.waveAsColumn\n",
    "    reshapedLong['diedInWave'] = reshapedLong.groupby('id')['diedInWaveTemp'].max()\n",
    "    reshapedLong['diedInWave'] = reshapedLong.groupby(['id'])['diedInWaveTemp'].transform(max)\n",
    "    reshapedLong.loc[reshapedLong.diedInWave.isna(), 'diedInWave'] = 10000\n",
    "    reshapedLong = reshapedLong.loc[reshapedLong.waveAsColumn <= reshapedLong.diedInWave]\n",
    "    reshapedLong.drop(['diedInWaveTemp', 'diedInWave'], axis='columns', inplace=True)\n",
    "    return reshapedLong\n",
    "    \n",
    "def getHazardRatios(untreatedEvents, treatedEvents, untreated_overallEvents, treated_overallEvents):\n",
    "\n",
    "    reshapedLong = getReshapedLongDF(untreatedEvents, treatedEvents, untreated_overallEvents, treated_overallEvents)\n",
    "    \n",
    "    cph = CoxPHFitter()\n",
    "    cph.fit(reshapedLong[['stroke', 'waveAsColumn', 'treatment']], duration_col='waveAsColumn', event_col='stroke', show_progress=False)\n",
    "    strokeHR = np.exp(cph.params_[0])\n",
    "\n",
    "    cph.fit(reshapedLong[['mi', 'waveAsColumn', 'treatment']], duration_col='waveAsColumn', event_col='mi', show_progress=False)\n",
    "    miHR = np.exp(cph.params_[0])\n",
    "    \n",
    "    miRR = (treated_overallEvents['mi'].sum()/treated_overallEvents['yearsOfObservation'].sum())/(untreated_overallEvents['mi'].sum()/untreated_overallEvents['yearsOfObservation'].sum())\n",
    "    strokeRR = (treated_overallEvents['stroke'].sum()/treated_overallEvents['yearsOfObservation'].sum())/(untreated_overallEvents['stroke'].sum()/untreated_overallEvents['yearsOfObservation'].sum())\n",
    "\n",
    "    \n",
    "    return (strokeHR, miHR, strokeRR, miRR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat simulation and summarize responses with recalibrated BP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "iteration: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-31:\n",
      "Process ForkPoolWorker-30:\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "Process ForkPoolWorker-37:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n"
     ]
    }
   ],
   "source": [
    "strokeHRs = []\n",
    "miHRs = []\n",
    "strokeRRs = []\n",
    "miRRs = []\n",
    "treatedEventsList = []\n",
    "overallTreatedEventsList = []\n",
    "untreatedEventsList = []\n",
    "overallUntreatedEventsList = []\n",
    "longDFs = []\n",
    "\n",
    "numIterations = 15\n",
    "numYears = 5\n",
    "\n",
    "\n",
    "for i in range(1,numIterations+1):\n",
    "    print(f\"\\niteration: {i}\")\n",
    "    baselinePop = NHANESDirectSamplePopulation(n=100000, year=2001)\n",
    "    baselinePop.advance_multi_process(numYears)\n",
    "    summarizePopulation(baselinePop, \"untreated\")\n",
    "    untreatedEvents = getDFForPopulation(baselinePop, numYears)\n",
    "    untreatedEventsList.append(untreatedEvents)\n",
    "    overallUntreatedEvents = getSimpleDFForPopulation(baselinePop)\n",
    "    overallUntreatedEventsList.append(overallUntreatedEvents)\n",
    "    print(f\"untreated events: {untreatedEventsList[i-1].stroke1.sum()}\\n\")\n",
    "\n",
    "    baselinePop.reset_to_baseline()\n",
    "    baselinePop.set_bp_treatment_strategy(addABPMed)\n",
    "    baselinePop.advance_multi_process(numYears)\n",
    "    summarizePopulation(baselinePop, \"treated\")\n",
    "    treatedEvents = getDFForPopulation(baselinePop, numYears)\n",
    "    treatedEventsList.append(treatedEvents)\n",
    "    overallTreatedEvents = getSimpleDFForPopulation(baselinePop)\n",
    "    overallTreatedEventsList.append(overallTreatedEvents)\n",
    "\n",
    "    longDFs.append(getReshapedLongDF(untreatedEvents, treatedEvents, overallUntreatedEvents, overallTreatedEvents))\n",
    "    strokeHR, miHR, strokeRR, miRR = getHazardRatios(untreatedEvents, treatedEvents, overallUntreatedEvents, overallTreatedEvents)\n",
    "    strokeHRs.append(strokeHR)\n",
    "    miHRs.append(miHR)\n",
    "    strokeRRs.append(strokeRR)\n",
    "    miRRs.append(miRR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.797526\n",
       "std       0.032867\n",
       "min       0.732929\n",
       "25%       0.777909\n",
       "50%       0.798264\n",
       "75%       0.825812\n",
       "max       0.847677\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(strokeRRs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.787780\n",
       "std       0.030984\n",
       "min       0.721667\n",
       "25%       0.768213\n",
       "50%       0.787165\n",
       "75%       0.809126\n",
       "max       0.841470\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(strokeHRs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.877046\n",
       "std       0.023630\n",
       "min       0.843356\n",
       "25%       0.860178\n",
       "50%       0.871512\n",
       "75%       0.886364\n",
       "max       0.921590\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(miHRs).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15.000000\n",
       "mean      0.883742\n",
       "std       0.023951\n",
       "min       0.851471\n",
       "25%       0.859612\n",
       "50%       0.882608\n",
       "75%       0.898686\n",
       "max       0.924226\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(miRRs).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, after considerable work, it seems that the recalibration is working very nicely and holding up over time\n",
    "Target stroke RR 0.79, actual (RR 0.80, HR 0.79). Target MI RR 0.87, actual (RR 0.88, HR 0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the RRs and HRs are consistent over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 1, stroke: 0.79221671485854, mi: 0.8735829852523217, death: 0.981262946412519\n",
      "year: 2, stroke: 0.7983494890566597, mi: 0.9023905286661105, death: 0.981262946412519\n",
      "year: 3, stroke: 0.797920581779661, mi: 0.8786809972109446, death: 0.981262946412519\n",
      "year: 4, stroke: 0.7854989332828539, mi: 0.8780390481503678, death: 0.981262946412519\n",
      "year: 5, stroke: 0.7792048437637534, mi: 0.8635951173406141, death: 0.981262946412519\n"
     ]
    }
   ],
   "source": [
    "numIterations = 15\n",
    "numYears=5\n",
    "\n",
    "for year in range(1,numYears+1):\n",
    "    strokeRR=0\n",
    "    miRR=0\n",
    "    deathRR=0\n",
    "    for eventsNum in range(0, numIterations):\n",
    "        strokeRR += treatedEventsList[eventsNum]['stroke' + str(year)].mean() / untreatedEventsList[eventsNum]['stroke' + str(year)].mean()\n",
    "        miRR += treatedEventsList[eventsNum]['mi' + str(year)].mean() / untreatedEventsList[eventsNum]['mi' + str(year)].mean()\n",
    "        deathRR += treatedEventsList[eventsNum]['dead' + str(year)].mean() / untreatedEventsList[eventsNum]['dead' + str(year)].mean()\n",
    "    strokeRR = strokeRR/numIterations\n",
    "    miRR = miRR/numIterations\n",
    "    deathRR = deathRR/numIterations\n",
    "\n",
    "\n",
    "    print(f\"year: {year}, stroke: {strokeRR}, mi: {miRR}, death: {deathRR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like they hold up nicely over time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior to testing recalibration, we explored whether it was possible to change the baseline simulation to get comarable RRs for the mean degree of BP lowering. After following this logic below, we concluded that it wasn't and went on to work on recalibration\n",
    "\n",
    "### The problem is that we appear to be under-estimating the relative risks compared to trials\n",
    "\n",
    "Expected Stroke RR from trials: <b>0.79</b> vs. simulation measured stroke RR: <b>0.95</b>\n",
    "<p>Expected CHD RR from trials:  <b>0.87</b> vs. simulation measured MI RR: <b>0.97</b>\n",
    "\n",
    "Theories:\n",
    "<ul>\n",
    "    <li><b> Random Error</b> - Certainly possible as a contributor as the trial-based estimates have considerable uncertaintly, but the magnitude of the differnce is too great to entirely put on random error.</li>\n",
    "    <li><b> Sample Selection</b> — The main difference comparing our synthetic trial popuation to the actual trials is that the BPs are slightly higher in our sample (by about 3/3 points). Given that ASCVD includes a sbp-sbp quadratic term and a sbp-age interaction, its possible that this is driving part of the story.\n",
    "        <p>In response, I tried 3 things:\n",
    "        <p><ol>\n",
    "            <li>Lowering the BPs for all patients in the sample by 3 points and re-running. This had a tiny effect on the relative risks (<i>both increasing to 0.72</i>). So no big effect.</li>\n",
    "            <li>Turning off the quadratic and interaction effects. Maybe the problem isn't the mean BPs but, the presence of extreme high BPs in our sample compared to the trials (which is hard to assess, becasue the trials only report means).<i>Turning off the quadratic and interaction effects increaes the effect sizes to 0.73></i></li>\n",
    "            <li>The other thought here woudl be about <b>race.</b> 16% of the simulated sample is Black. I'm not sure what that looks like in teh pooled analysis. But, given that race features heavily in ASCVD, its a conceivable problem. Turning off all race effects led to an effect of <i>0.74</i> for stroke and no change for MI, <i>0.71</i></li><p>\n",
    "        <li>Turning off all of those effects change the RR to <i>0.73</i> for stroke and no change for MI, <i>0.71</i> - so race seems like its probably the most important seleectkon factor and may be drivin the other factors...but, on teh whole selection factors (that aren't of the form \"Peopel in trials have better outcomes\") dont' seem to explain much of the gap</li>\n",
    "\n",
    "        </ol>  \n",
    "    </li>\n",
    "    <li><b> Measurement Error</b> — While always a condern with BPs, I have a hard time seeing how it would drive our findings here. First, the measurements from trials are (presumably) decent. Second, there is a fair bit of data supporting the BP lowering effect — those estimates should be fairly precise and both random error and non-differential measurement error shoudl balance out do to sample size. Third, if anything, the trial-measured BP lowering effect seems pretty small — and yet we're still over-estimating the BP lowering effect.</li>\n",
    "    <li><b> Heterogeneity of BP lowering? </b> — If it were that patients with very high blood pressures had a larger effect to a single BP med, then we might miss the boat by giving everybody a fixed 5/3 BP reduction. However, without having anything to parameterize this off...its hard to do anything more than just to explore it.\n",
    "    <ul>\n",
    "    <li> Didn't build a model in whom BP lowering occurs (don't think we know...), but drew BP lowering from a distribution - possibly a very small effect: stroke RR <i>0.72</i>, MI: <i>0.71</i></li></ul>\n",
    "    </li>\n",
    "    <li><b>Confounding in ASCVD</b> — This seems most plausible to me. It seems pretty believale that patients with very high BPs also have other factors that drive their long-term risk that aren't well measured. So, the idea that ASCVD over-estimates the effect of BP lowring at high BPs is plausible. Unless we could account for that confouder (any papers on ASCVD and SES?), I thikn this means that we have to put in a recalibration factor to try and get our estimates to line up.</li>\n",
    "    <li><b>Inaccurate trial estimation of treatment effect</b> — Well, if that's the case, we're screwed. We need the trials for treatment effect. I guess its possible — the trial population may be healthier than the ASCVD population, for example, and perhaps there is some sort of ceiling effect. But, that seems unlikely given that the predicted risk in the trials lines up almost perfectly with ASCVD</li>\n",
    "\n",
    "<li><b>Period effects</b> — Doesn’t make a ton of sense though…those are probably leading to lower RRs over time and the trials, based on older data (right?) have less BP effect than the cohorts.</li>\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code below is for summarizing and stratifying effects across age and BP deciles...it was an early check, but not the current goal of the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at relative risk across age deciles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageBpPop = pd.DataFrame({'mi': [x.has_mi_during_simulation() for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke' : [x.has_stroke_during_simulation() for i,x in  baselinePop._people.iteritems()],\n",
    "                         'age' : [x._age[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'sbp' : [x._sbp[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dbp' : [x._dbp[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'priorStrokeMI' : [x.has_stroke_prior_to_simulation() or x.has_mi_prior_to_simulation() for i,x in  baselinePop._people.iteritems()],\n",
    "                         'currentSmoker' : [x._smokingStatus==SmokingStatus.CURRENT for i,x in  baselinePop._people.iteritems()],\n",
    "                         'hdl' : [x._hdl[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'a1c' : [x._a1c[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead' : [x.is_dead() for i,x in  baselinePop._people.iteritems()],\n",
    "                         'allhat' : [x.allhat_candidate(0) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'yearsOfObservation' : [x.years_in_simulation() for i, x in baselinePop._people.iteritems()]})\n",
    "\n",
    "ageBpPop['ageDeciles'] = pd.qcut(ageBpPop.age, 5, labels=range(1,6))\n",
    "ageBpPop['sbpDeciles'] = pd.qcut(ageBpPop.sbp, 5, labels=range(1,6))\n",
    "\n",
    "\n",
    "ageBpTreatedPop = pd.DataFrame({'mi': [x.has_mi_during_simulation() for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke' : [x.has_stroke_during_simulation() for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'age' : [x._age[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'sbp' : [x._sbp[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dbp' : [x._dbp[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'priorStrokeMI' : [x.has_stroke_prior_to_simulation() or x.has_mi_prior_to_simulation() for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'currentSmoker' : [x._smokingStatus==SmokingStatus.CURRENT for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'hdl' : [x._hdl[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'a1c' : [x._a1c[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead' : [x.is_dead() for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'allhat' : [x.allhat_candidate(0) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'yearsOfObservation' : [x.years_in_simulation() for i, x in popExtraBpMed._people.iteritems()]})\n",
    "\n",
    "\n",
    "ageBpTreatedPop['ageDeciles'] = pd.qcut(ageBpTreatedPop.age, 5, labels=range(1,6))\n",
    "ageBpTreatedPop['sbpDeciles'] = pd.qcut(ageBpTreatedPop.sbp, 5, labels=range(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(np.arange(0.85, 5.85, 1), ageBpPop.groupby('ageDeciles')['mi'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(np.arange(1.15, 6.15, 1), ageBpTreatedPop.groupby('ageDeciles')['mi'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.title(\"Mi Risk, by age decile\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(np.arange(0.85, 5.85, 1), ageBpPop.groupby('sbpDeciles')['mi'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(np.arange(1.15, 6.15, 1), ageBpTreatedPop.groupby('sbpDeciles')['mi'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.title(\"MI risk by SBP decile\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(np.arange(0.85, 5.85, 1), ageBpPop.groupby('ageDeciles')['stroke'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(np.arange(1.15, 6.15, 1), ageBpTreatedPop.groupby('ageDeciles')['stroke'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.legend()\n",
    "plt.title(\"Stroke Risk, by age decile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(np.arange(0.85, 5.85, 1), ageBpPop.groupby('sbpDeciles')['stroke'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(np.arange(1.15, 6.15, 1), ageBpTreatedPop.groupby('sbpDeciles')['stroke'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.legend()\n",
    "plt.title(\"Stroke Risk, by SBP decile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Relative MI risk reduction by age decile\")\n",
    "print((ageBpPop.groupby('ageDeciles')['mi'].mean() -ageBpTreatedPop.groupby('ageDeciles')['mi'].mean())/ageBpPop.groupby('ageDeciles')['mi'].mean())\n",
    "\n",
    "print (\"Relative stroke risk reduction by age decile\")\n",
    "print((ageBpPop.groupby('ageDeciles')['stroke'].mean() -ageBpTreatedPop.groupby('ageDeciles')['stroke'].mean())/ageBpPop.groupby('ageDeciles')['stroke'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageBpPop.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageBpTreatedPop.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(1, ageBpPop['mi'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(2, ageBpTreatedPop['mi'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.legend()\n",
    "plt.title(\"MI Risk in allhat-type population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(1, ageBpPop['stroke'].mean()*100, width=0.25, label = \"Baseline\")\n",
    "plt.bar(2, ageBpTreatedPop['stroke'].mean()*100, width=0.25, label=\"Add BP Med\")\n",
    "plt.legend()\n",
    "plt.title(\"Stroke Risk in allhat-type population\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Relative MI risk for one BP med in ALLHAT: {(ageBpTreatedPop['mi'].sum()/ageBpTreatedPop['yearsOfObservation'].sum())/(ageBpPop['mi'].sum()/ageBpTreatedPop['yearsOfObservation'].sum()):.2f}\")\n",
    "print (f\"Relative stroke risk for one BP med in ALLHAT: {(ageBpTreatedPop['stroke'].sum()/ageBpTreatedPop['yearsOfObservation'].sum())/(ageBpPop['stroke'].sum()/ageBpTreatedPop['yearsOfObservation'].sum()):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Across 4 runs of the simulation, we got:\n",
    "<ol>\n",
    "    <li>Relative <b>MI</b> risk for one BP med in ALLHAT: 0.72\n",
    "        <p>Relative <b>stroke</b> risk for one BP med in ALLHAT: 0.64\n",
    "    </li>\n",
    "\n",
    "<p>\n",
    "<li>Relative <b>MI</b> risk for one BP med in ALLHAT: 0.73\n",
    "    <p>Relative <b>stroke</b> risk for one BP med in ALLHAT: 0.74\n",
    "</li>\n",
    "\n",
    "<p><li>Relative <b>MI</b> risk for one BP med in ALLHAT: 0.66\n",
    "    <p>Relative <b>stroke</b> risk for one BP med in ALLHAT: 0.67\n",
    "</li>\n",
    "\n",
    "<P><li>\n",
    "    Relative <b>MI</b> risk for one BP med in ALLHAT: 0.75\n",
    "    <p>Relative <b>stroke</b> risk for one BP med in ALLHAT: 0.70\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  for stroke, the relative risk should be around 0.62-0.77 — so we're over estimating risk by a little bit...\n",
    "2. for MI, the relative risk shoudl be around 0.78-0.85...so, we're over estimating risk by quite a bit....\n",
    "\n",
    "### conclusions\n",
    "1. We're probably estimating the overall risk reasonably accurately, although perhpaps a little aggressively (we're around 0.72 for MI and 0.67 for sroke)\n",
    "2. Our models aren't pickig up the role of blood pressure lowering for stroke >> MI\n",
    "\n",
    "### questions\n",
    "1. What is the right setup for a comparison? Duration? \n",
    "2. What is the right treamtent comparison, \"add one med in year one...and then some people non-adhere over 5 years is the current model\"\n",
    "3. Could our divergence just be that our population is a bit differnet than ALLHAT? (In spite of the same inclusion criteria, we got a somewhat differnet sample...)\n",
    "4. Coudl the divergence be for failing to account for mortality? Should I estimate HR censoring on death? Actually...its quite clear that I shoudl...let me do that...\n",
    "5. Is the place to focus on the event partitioning model? Its basically just an age model (more strokes amongst the old, more MIs amongst the young...). Should we include BP treatment into the model (i.e. more treamtent = fewer strokes?)\n",
    "6. How importance is getting this issue \"right\" for the BP cog results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreatedEvents = pd.DataFrame({'mi1': [x.has_mi_during_wave(0) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi2': [x.has_mi_during_wave(1) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi3': [x.has_mi_during_wave(2) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi4': [x.has_mi_during_wave(3) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi5': [x.has_mi_during_wave(4) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke1': [x.has_stroke_during_wave(0) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke2': [x.has_stroke_during_wave(1) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke3': [x.has_stroke_during_wave(2) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke4': [x.has_stroke_during_wave(3) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke5': [x.has_stroke_during_wave(4) for i,x in  baselinePop._people.iteritems()],                         'age' : [x._age[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead1': [x.is_dead() and len(x._age)==1 for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead2': [x.is_dead() and len(x._age)==2 for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead3': [x.is_dead() and len(x._age)==3 for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead4': [x.is_dead() and len(x._age)==4 for i,x in  baselinePop._people.iteritems()],\n",
    "                         'dead5': [x.is_dead() and len(x._age)==5 for i,x in  baselinePop._people.iteritems()],                         \n",
    "                         'age' : [x._age[0] for i,x in  baselinePop._people.iteritems()],\n",
    "                         'allhat' : [x.allhat_candidate(0) for i,x in  baselinePop._people.iteritems()]})\n",
    "\n",
    "treatedEvents = pd.DataFrame({'mi1': [x.has_mi_during_wave(0) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi2': [x.has_mi_during_wave(1) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi3': [x.has_mi_during_wave(2) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi4': [x.has_mi_during_wave(3) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi5': [x.has_mi_during_wave(4) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke1': [x.has_stroke_during_wave(0) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke2': [x.has_stroke_during_wave(1) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke3': [x.has_stroke_during_wave(2) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke4': [x.has_stroke_during_wave(3) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke5': [x.has_stroke_during_wave(4) for i,x in  popExtraBpMed._people.iteritems()],                         \n",
    "                         'age' : [x._age[0] for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead1': [x.is_dead() and len(x._age)==1 for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead2': [x.is_dead() and len(x._age)==2 for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead3': [x.is_dead() and len(x._age)==3 for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead4': [x.is_dead() and len(x._age)==4 for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'dead5': [x.is_dead() and len(x._age)==5 for i,x in  popExtraBpMed._people.iteritems()],                         \n",
    "                         'allhat' : [x.allhat_candidate(0) for i,x in  popExtraBpMed._people.iteritems()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreatedEvents['treatment'] = 0\n",
    "treatedEvents['treatment'] = 1\n",
    "allEvents = pd.concat([untreatedEvents, treatedEvents], ignore_index=True)\n",
    "allEvents['id'] = allEvents.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshapedLong = pd.wide_to_long(allEvents,stubnames=['mi', 'stroke', 'dead'], i='id', j='wave')\n",
    "reshapedLong = reshapedLong.sort_index()\n",
    "reshapedLong['waveAsColumn'] = reshapedLong.index.get_level_values('wave')\n",
    "reshapedLong.loc[reshapedLong.dead, 'diedInWaveTemp'] = reshapedLong.waveAsColumn\n",
    "reshapedLong['diedInWave'] = reshapedLong.groupby('id')['diedInWaveTemp'].max()\n",
    "reshapedLong['diedInWave'] = reshapedLong.groupby(['id'])['diedInWaveTemp'].transform(max)\n",
    "reshapedLong = reshapedLong.loc[reshapedLong.waveAsColumn <= reshapedLong.diedInWave]\n",
    "reshapedLong.drop(['diedInWaveTemp', 'diedInWave'], axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(reshapedLong[['stroke', 'waveAsColumn', 'treatment']], duration_col='waveAsColumn', event_col='stroke', show_progress=False)\n",
    "print(f\"\\nHR of treatment on stroke: {np.exp(cph.params_[0]):.2f}\")\n",
    "\n",
    "cph.fit(reshapedLong[['mi', 'waveAsColumn', 'treatment']], duration_col='waveAsColumn', event_col='mi', show_progress=False)\n",
    "print(f\"\\nHR of treatment on MI: {np.exp(cph.params_[0]):.2f}\")\n",
    "\n",
    "\n",
    "#cph.print_summary()  # access the results using cph.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### possible theories: \n",
    "<ol><li> applying a fixed point blood pressure lowering effect is unrealistic...we need to sample from distributions, although i doubt that changes things much...</li>\n",
    "<li> is there a duaraiton effect here? the estimates are based off of multiple eyars...looking at one year might miss the boat because the highest risk peopel are jumping first...</li>\n",
    "<li> population parameters don't line up with ALLHAT (our population is older, BPs are quite a bit higher here — so maybe we haven't gotten the population right. although, i'm not sure about the direction of the relative effcts, this may be workign in our favor</li>\n",
    "<li> observational BP lowering estimates are fundamentally diconnected from trial based estimates (i.e. ASCVD is not calibrated with the trials - could directly test this with the model...</li>\n",
    "<li> what does the specification of a causal effect mean here? does a BP med cause a 4 point constant reduction in your BP? does it lower your BP one and then you return to baseline?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcm.outcome import OutcomeType\n",
    "\n",
    "eventsByAgeUntreated = pd.DataFrame({'stroke0' : [x.has_stroke_during_wave(0) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke1' : [x.has_stroke_during_wave(1) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke2' : [x.has_stroke_during_wave(2) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke3' : [x.has_stroke_during_wave(3) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'stroke4' : [x.has_stroke_during_wave(4) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi0' : [x.has_mi_during_wave(0) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi1' : [x.has_mi_during_wave(1) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi2' : [x.has_mi_during_wave(2) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi3' : [x.has_mi_during_wave(3) for i,x in  baselinePop._people.iteritems()],\n",
    "                         'mi4' : [x.has_mi_during_wave(4) for i,x in  baselinePop._people.iteritems()]})\n",
    "\n",
    "eventsByAgeTreated = pd.DataFrame({'stroke0' : [x.has_stroke_during_wave(0) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke1' : [x.has_stroke_during_wave(1) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke2' : [x.has_stroke_during_wave(2) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke3' : [x.has_stroke_during_wave(3) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'stroke4' : [x.has_stroke_during_wave(4) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi0' : [x.has_mi_during_wave(0) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi1' : [x.has_mi_during_wave(1) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi2' : [x.has_mi_during_wave(2) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi3' : [x.has_mi_during_wave(3) for i,x in  popExtraBpMed._people.iteritems()],\n",
    "                         'mi4' : [x.has_mi_during_wave(4) for i,x in  popExtraBpMed._people.iteritems()]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strokeUntreated = [eventsByAgeUntreated.stroke0.mean(),\n",
    "                        eventsByAgeUntreated.stroke1.mean(),\n",
    "                        eventsByAgeUntreated.stroke2.mean(),\n",
    "                        eventsByAgeUntreated.stroke3.mean(),\n",
    "                        eventsByAgeUntreated.stroke4.mean()]\n",
    "strokeUntreatedError = np.array([eventsByAgeUntreated.stroke0.sem(),\n",
    "                        eventsByAgeUntreated.stroke1.sem(),\n",
    "                        eventsByAgeUntreated.stroke2.sem(),\n",
    "                        eventsByAgeUntreated.stroke3.sem(),\n",
    "                        eventsByAgeUntreated.stroke4.sem()])*1.96\n",
    "strokeTreated = [eventsByAgeTreated.stroke0.mean(),\n",
    "                        eventsByAgeTreated.stroke1.mean(),\n",
    "                        eventsByAgeTreated.stroke2.mean(),\n",
    "                        eventsByAgeTreated.stroke3.mean(),\n",
    "                        eventsByAgeTreated.stroke4.mean()]\n",
    "strokeTreatedError = np.array([eventsByAgeTreated.stroke0.sem(),\n",
    "                        eventsByAgeTreated.stroke1.sem(),\n",
    "                        eventsByAgeTreated.stroke2.sem(),\n",
    "                        eventsByAgeTreated.stroke3.sem(),\n",
    "                        eventsByAgeTreated.stroke4.sem()])*1.96\n",
    "\n",
    "plt.bar(np.arange(0,5),strokeUntreated ,yerr=strokeUntreatedError, width=0.4, capsize=3,label=\"Untreated\")\n",
    "plt.bar(np.arange(0.4,5.4, 1), strokeTreated, yerr=strokeTreatedError, width=0.4, capsize=3, label=\"Treated\")\n",
    "plt.legend(loc=2)\n",
    "plt.title(\"Stroke Rates by temporal wave with treatment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(strokeTreated)/pd.Series(strokeUntreated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miUntreated = [eventsByAgeUntreated.mi0.mean(),\n",
    "                        eventsByAgeUntreated.mi1.mean(),\n",
    "                        eventsByAgeUntreated.mi2.mean(),\n",
    "                        eventsByAgeUntreated.mi3.mean(),\n",
    "                        eventsByAgeUntreated.mi4.mean()]\n",
    "\n",
    "miUntreatedError = np.array([eventsByAgeUntreated.mi0.sem(),\n",
    "                        eventsByAgeUntreated.mi1.sem(),\n",
    "                        eventsByAgeUntreated.mi2.sem(),\n",
    "                        eventsByAgeUntreated.mi3.sem(),\n",
    "                        eventsByAgeUntreated.mi4.sem()])*1.96\n",
    "miTreated = [eventsByAgeTreated.mi0.mean(),\n",
    "                        eventsByAgeTreated.mi1.mean(),\n",
    "                        eventsByAgeTreated.mi2.mean(),\n",
    "                        eventsByAgeTreated.mi3.mean(),\n",
    "                        eventsByAgeTreated.mi4.mean()]\n",
    "miTreatedError = np.array([eventsByAgeTreated.mi0.sem(),\n",
    "                        eventsByAgeTreated.mi1.sem(),\n",
    "                        eventsByAgeTreated.mi2.sem(),\n",
    "                        eventsByAgeTreated.mi3.sem(),\n",
    "                        eventsByAgeTreated.mi4.sem()])*1.96\n",
    "\n",
    "plt.bar(np.arange(0,5), miUntreated, yerr=miUntreatedError, width=0.4, capsize=3, label=\"Untreated\")\n",
    "plt.bar(np.arange(0.4,5.4, 1), miTreated, yerr=miTreatedError, width=0.4, capsize=3, label=\"Treated\")\n",
    "plt.legend(loc=2)\n",
    "plt.title(\"MI Rates by temporal wave with treatment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(miTreated)/pd.Series(miUntreated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
